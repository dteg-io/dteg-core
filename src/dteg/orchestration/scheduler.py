"""
ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“ˆ

íŒŒì´í”„ë¼ì¸ì˜ ìŠ¤ì¼€ì¤„ë§ ë° ì‹¤í–‰ ê´€ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ êµ¬í˜„
"""
import logging
import time
from datetime import datetime
from typing import Dict, List, Optional, Callable, Union
import croniter
import uuid
from pathlib import Path
import os
import json

from dteg.core.pipeline import Pipeline
from dteg.core.config import PipelineConfig

logger = logging.getLogger(__name__)

class ScheduleConfig:
    """íŒŒì´í”„ë¼ì¸ ìŠ¤ì¼€ì¤„ ì„¤ì • í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        pipeline_config: Union[PipelineConfig, str, Path],
        cron_expression: str,
        enabled: bool = True,
        dependencies: List[str] = None,
        max_retries: int = 3,
        retry_delay: int = 300  # 5ë¶„
    ):
        """
        ìŠ¤ì¼€ì¤„ ì„¤ì • ì´ˆê¸°í™”
        
        Args:
            pipeline_config: íŒŒì´í”„ë¼ì¸ ì„¤ì • ê°ì²´ ë˜ëŠ” ì„¤ì • íŒŒì¼ ê²½ë¡œ
            cron_expression: Cron í‘œí˜„ì‹ (ì˜ˆ: "0 0 * * *" - ë§¤ì¼ ìì •)
            enabled: ìŠ¤ì¼€ì¤„ í™œì„±í™” ì—¬ë¶€
            dependencies: ì´ íŒŒì´í”„ë¼ì¸ì˜ ì‹¤í–‰ ì „ì— ì™„ë£Œë˜ì–´ì•¼ í•˜ëŠ” íŒŒì´í”„ë¼ì¸ ID ëª©ë¡
            max_retries: ì‹¤íŒ¨ ì‹œ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            retry_delay: ì¬ì‹œë„ ê°„ ì§€ì—° ì‹œê°„(ì´ˆ)
        """
        self.id = str(uuid.uuid4())
        self.pipeline_config = pipeline_config
        self.cron_expression = cron_expression
        self.enabled = enabled
        self.dependencies = dependencies or []
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        self.next_run = self._get_next_run()
        
        # ìœ íš¨ì„± ê²€ì‚¬
        if not croniter.croniter.is_valid(cron_expression):
            raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ Cron í‘œí˜„ì‹: {cron_expression}")
    
    def _get_next_run(self) -> datetime:
        """ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°"""
        cron = croniter.croniter(self.cron_expression, datetime.now())
        return cron.get_next(ret_type=datetime)
    
    def update_next_run(self):
        """ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ì—…ë°ì´íŠ¸"""
        cron = croniter.croniter(self.cron_expression, datetime.now())
        self.next_run = cron.get_next(ret_type=datetime)

    def to_dict(self) -> Dict:
        """ì‚¬ì „ í˜•íƒœë¡œ ë³€í™˜"""
        pipeline_config_str = str(self.pipeline_config)
        if isinstance(self.pipeline_config, PipelineConfig):
            pipeline_config_str = self.pipeline_config.pipeline_id
            
        return {
            "id": self.id,
            "pipeline_config": pipeline_config_str,
            "cron_expression": self.cron_expression,
            "enabled": self.enabled,
            "dependencies": self.dependencies,
            "max_retries": self.max_retries,
            "retry_delay": self.retry_delay,
            "next_run": self.next_run.isoformat() if self.next_run else None
        }
    
    @classmethod
    def from_dict(cls, data: Dict, schedule_dir: Optional[Path] = None) -> 'ScheduleConfig':
        """ì‚¬ì „ì—ì„œ ìŠ¤ì¼€ì¤„ ì„¤ì • ë³µì›"""
        # pipeline_config ì²˜ë¦¬
        pipeline_config = data["pipeline_config"]
        
        # ê²½ë¡œì¸ ê²½ìš° í™•ì¸
        if isinstance(pipeline_config, str) and schedule_dir and "/" in pipeline_config:
            # ìƒëŒ€ ê²½ë¡œë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸
            pipeline_path = Path(pipeline_config)
            if not pipeline_path.exists() and schedule_dir:
                # ìŠ¤ì¼€ì¤„ ë””ë ‰í† ë¦¬ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ ì‹œë„
                alt_path = schedule_dir.parent / pipeline_config
                if alt_path.exists():
                    pipeline_config = str(alt_path)
        
        instance = cls(
            pipeline_config=pipeline_config,
            cron_expression=data["cron_expression"],
            enabled=data["enabled"],
            dependencies=data["dependencies"],
            max_retries=data["max_retries"],
            retry_delay=data["retry_delay"]
        )
        
        # ID ë³µì›
        instance.id = data["id"]
        
        # ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ë³µì›
        if data.get("next_run"):
            instance.next_run = datetime.fromisoformat(data["next_run"])
        else:
            instance.update_next_run()
            
        return instance


class ExecutionRecord:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê¸°ë¡ í´ë˜ìŠ¤"""
    
    def __init__(self, schedule_id: str, pipeline_id: str):
        """
        ì‹¤í–‰ ê¸°ë¡ ì´ˆê¸°í™”
        
        Args:
            schedule_id: ìŠ¤ì¼€ì¤„ ID
            pipeline_id: íŒŒì´í”„ë¼ì¸ ID
        """
        self.id = str(uuid.uuid4())
        self.schedule_id = schedule_id
        self.pipeline_id = pipeline_id
        self.start_time = datetime.now()
        self.end_time = None
        self.status = "RUNNING"  # RUNNING, SUCCESS, FAILED, RETRYING
        self.retry_count = 0
        self.error_message = None
        self.logs = []
    
    def complete(self, success: bool, error_message: Optional[str] = None):
        """
        ì‹¤í–‰ ì™„ë£Œ ì²˜ë¦¬
        
        Args:
            success: ì„±ê³µ ì—¬ë¶€
            error_message: ì˜¤ë¥˜ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
        """
        self.end_time = datetime.now()
        self.status = "SUCCESS" if success else "FAILED"
        self.error_message = error_message
    
    def retry(self, error_message: str):
        """
        ì¬ì‹œë„ ì²˜ë¦¬
        
        Args:
            error_message: ì˜¤ë¥˜ ë©”ì‹œì§€
        """
        self.retry_count += 1
        self.status = "RETRYING"
        self.error_message = error_message
    
    def to_dict(self) -> Dict:
        """ì‚¬ì „ í˜•íƒœë¡œ ë³€í™˜"""
        return {
            "id": self.id,
            "schedule_id": self.schedule_id,
            "pipeline_id": self.pipeline_id,
            "start_time": self.start_time.isoformat(),
            "end_time": self.end_time.isoformat() if self.end_time else None,
            "status": self.status,
            "retry_count": self.retry_count,
            "error_message": self.error_message,
            "logs": self.logs
        }


class Scheduler:
    """íŒŒì´í”„ë¼ì¸ ìŠ¤ì¼€ì¤„ëŸ¬ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 history_dir: Optional[Union[str, Path]] = None,
                 schedule_dir: Optional[Union[str, Path]] = None,
                 on_execution_complete: Optional[Callable[[ExecutionRecord], None]] = None):
        """
        ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            history_dir: ì‹¤í–‰ ì´ë ¥ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: ~/.dteg/history)
            schedule_dir: ìŠ¤ì¼€ì¤„ ì„¤ì •ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: ~/.dteg/schedules)
            on_execution_complete: ì‹¤í–‰ ì™„ë£Œ ì‹œ í˜¸ì¶œë  ì½œë°± í•¨ìˆ˜
        """
        self.schedules: Dict[str, ScheduleConfig] = {}
        self.running_executions: Dict[str, ExecutionRecord] = {}
        self.completed_executions: List[ExecutionRecord] = []
        self.on_execution_complete = on_execution_complete
        
        # ì´ë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if history_dir is None:
            history_dir = Path.home() / ".dteg" / "history"
        self.history_dir = Path(history_dir)
        self.history_dir.mkdir(parents=True, exist_ok=True)
        
        # ìŠ¤ì¼€ì¤„ ë””ë ‰í† ë¦¬ ì„¤ì •
        if schedule_dir is None:
            schedule_dir = Path.home() / ".dteg" / "schedules"
        self.schedule_dir = Path(schedule_dir)
        self.schedule_dir.mkdir(parents=True, exist_ok=True)
        
        # ì´ì „ ì‹¤í–‰ ì´ë ¥ ë° ìŠ¤ì¼€ì¤„ ë¡œë“œ
        self._load_history()
        self._load_schedules()
    
    def add_schedule(self, schedule_config: ScheduleConfig) -> str:
        """
        ìŠ¤ì¼€ì¤„ ì¶”ê°€
        
        Args:
            schedule_config: ìŠ¤ì¼€ì¤„ ì„¤ì • ê°ì²´
            
        Returns:
            ì¶”ê°€ëœ ìŠ¤ì¼€ì¤„ì˜ ID
        """
        self.schedules[schedule_config.id] = schedule_config
        logger.info(f"ìŠ¤ì¼€ì¤„ ì¶”ê°€ë¨: {schedule_config.id} - ë‹¤ìŒ ì‹¤í–‰: {schedule_config.next_run}")
        # ìŠ¤ì¼€ì¤„ ì €ì¥
        self._save_schedules()
        return schedule_config.id
    
    def remove_schedule(self, schedule_id: str) -> bool:
        """
        ìŠ¤ì¼€ì¤„ ì œê±°
        
        Args:
            schedule_id: ìŠ¤ì¼€ì¤„ ID
            
        Returns:
            ì œê±° ì„±ê³µ ì—¬ë¶€
        """
        if schedule_id in self.schedules:
            del self.schedules[schedule_id]
            logger.info(f"ìŠ¤ì¼€ì¤„ ì œê±°ë¨: {schedule_id}")
            # ìŠ¤ì¼€ì¤„ ì €ì¥
            self._save_schedules()
            return True
        return False
    
    def get_schedule(self, schedule_id: str) -> Optional[ScheduleConfig]:
        """ìŠ¤ì¼€ì¤„ IDë¡œ ìŠ¤ì¼€ì¤„ ì¡°íšŒ"""
        return self.schedules.get(schedule_id)
    
    def get_all_schedules(self) -> List[ScheduleConfig]:
        """ëª¨ë“  ìŠ¤ì¼€ì¤„ ì¡°íšŒ"""
        return list(self.schedules.values())
    
    def update_schedule(self, schedule_id: str, **kwargs) -> bool:
        """
        ìŠ¤ì¼€ì¤„ ì—…ë°ì´íŠ¸
        
        Args:
            schedule_id: ìŠ¤ì¼€ì¤„ ID
            **kwargs: ì—…ë°ì´íŠ¸í•  ì†ì„±ê³¼ ê°’
            
        Returns:
            ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        if schedule_id not in self.schedules:
            return False
        
        schedule = self.schedules[schedule_id]
        for key, value in kwargs.items():
            if hasattr(schedule, key):
                setattr(schedule, key, value)
        
        # Cron í‘œí˜„ì‹ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìœ¼ë©´ ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ì¬ê³„ì‚°
        if "cron_expression" in kwargs:
            schedule.update_next_run()
        
        logger.info(f"ìŠ¤ì¼€ì¤„ ì—…ë°ì´íŠ¸ë¨: {schedule_id}")
        # ìŠ¤ì¼€ì¤„ ì €ì¥
        self._save_schedules()
        return True
    
    def run_once(self):
        """
        ì‹¤í–‰ ëŒ€ê¸° ì¤‘ì¸ ìŠ¤ì¼€ì¤„ì„ í™•ì¸í•˜ê³  ì‹¤í–‰
        """
        now = datetime.now()
        
        logger.debug(f"ìŠ¤ì¼€ì¤„ í™•ì¸ ì¤‘... (í˜„ì¬ ì‹œê°„: {now.strftime('%Y-%m-%d %H:%M:%S')})")
        pending_schedule_count = 0
        executed_count = 0
        
        # ì‹¤í–‰ ëŒ€ê¸° ì¤‘ì¸ ìŠ¤ì¼€ì¤„ í™•ì¸
        for schedule_id, schedule in self.schedules.items():
            if not schedule.enabled:
                logger.debug(f"ìŠ¤ì¼€ì¤„ {schedule_id}ëŠ” ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤")
                continue
            
            logger.debug(f"ìŠ¤ì¼€ì¤„ {schedule_id} ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„: {schedule.next_run.strftime('%Y-%m-%d %H:%M:%S')}")
            
            if schedule.next_run <= now:
                pending_schedule_count += 1
                pipeline_id = getattr(schedule.pipeline_config, 'pipeline_id', str(schedule.pipeline_config))
                
                logger.info(f"ğŸ”” ì‹¤í–‰ ëŒ€ê¸° ì¤‘ì¸ ìŠ¤ì¼€ì¤„ ë°œê²¬: {schedule_id} (íŒŒì´í”„ë¼ì¸: {pipeline_id})")
                
                # ì˜ì¡´ì„± í™•ì¸
                if self._check_dependencies(schedule):
                    logger.info(f"â–¶ï¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘: {schedule_id} â†’ {pipeline_id}")
                    self._run_pipeline(schedule)
                    schedule.update_next_run()
                    executed_count += 1
                    logger.info(f"â­ï¸ ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ì—…ë°ì´íŠ¸: {schedule.next_run.strftime('%Y-%m-%d %H:%M:%S')}")
                    # ìŠ¤ì¼€ì¤„ ì €ì¥ (ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ì—…ë°ì´íŠ¸)
                    self._save_schedules()
                else:
                    logger.warning(f"âš ï¸ ìŠ¤ì¼€ì¤„ {schedule_id}ì˜ ì˜ì¡´ì„±ì´ ì¶©ì¡±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒ ê¸°íšŒì— ì¬ì‹œë„í•©ë‹ˆë‹¤.")
        
        # ì‹¤í–‰ ìš”ì•½ ë©”ì‹œì§€
        if pending_schedule_count > 0:
            logger.info(f"ğŸ“Š ìŠ¤ì¼€ì¤„ ì‹¤í–‰ ìš”ì•½: ëŒ€ê¸° {pending_schedule_count}ê°œ ì¤‘ {executed_count}ê°œ ì‹¤í–‰ë¨")
    
    def _check_dependencies(self, schedule: ScheduleConfig) -> bool:
        """
        ìŠ¤ì¼€ì¤„ì˜ ì˜ì¡´ì„± ì¶©ì¡± ì—¬ë¶€ í™•ì¸
        
        Args:
            schedule: ìŠ¤ì¼€ì¤„ ì„¤ì • ê°ì²´
            
        Returns:
            ì˜ì¡´ì„± ì¶©ì¡± ì—¬ë¶€
        """
        if not schedule.dependencies:
            return True
            
        # ì˜ì¡´ íŒŒì´í”„ë¼ì¸ì˜ ìµœê·¼ ì‹¤í–‰ ìƒíƒœ í™•ì¸
        for dep_id in schedule.dependencies:
            dep_successful = False
            
            # ì™„ë£Œëœ ì‹¤í–‰ ëª©ë¡ì—ì„œ í™•ì¸
            for exec_record in reversed(self.completed_executions):
                if exec_record.pipeline_id == dep_id and exec_record.status == "SUCCESS":
                    dep_successful = True
                    break
            
            if not dep_successful:
                return False
                
        return True
    
    def _run_pipeline(self, schedule: ScheduleConfig):
        """
        íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            schedule: ìŠ¤ì¼€ì¤„ ì„¤ì • ê°ì²´
        """
        # íŒŒì´í”„ë¼ì¸ ì„¤ì • ë¡œë“œ
        if isinstance(schedule.pipeline_config, (str, Path)):
            config = PipelineConfig.from_yaml(schedule.pipeline_config)
        else:
            config = schedule.pipeline_config
        
        # ì‹¤í–‰ ê¸°ë¡ ìƒì„±
        pipeline_id = getattr(config, "pipeline_id", str(schedule.pipeline_config))
        execution = ExecutionRecord(schedule.id, pipeline_id)
        self.running_executions[execution.id] = execution
        
        try:
            # ëª…í™•í•˜ê³  ëˆˆì— ë„ëŠ” ì‹¤í–‰ ë©”ì‹œì§€ ì¶œë ¥
            logger.info("=" * 60)
            logger.info(f"ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘: {pipeline_id} (ìŠ¤ì¼€ì¤„: {schedule.id})")
            logger.info(f"â° ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info("=" * 60)
            
            # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            pipeline = Pipeline(config)
            pipeline.run()
            
            # ì‹¤í–‰ ì™„ë£Œ ì²˜ë¦¬
            execution.complete(success=True)
            
            # ì‹¤í–‰ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥
            logger.info("=" * 60)
            logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ: {pipeline_id} (ìŠ¤ì¼€ì¤„: {schedule.id})")
            logger.info(f"â° ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info("=" * 60)
            
        except Exception as e:
            error_msg = str(e)
            
            # ì‹¤í–‰ ì‹¤íŒ¨ ë©”ì‹œì§€ ì¶œë ¥
            logger.error("=" * 60)
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {pipeline_id} (ìŠ¤ì¼€ì¤„: {schedule.id})")
            logger.error(f"ğŸ”¥ ì˜¤ë¥˜: {error_msg}")
            logger.error("=" * 60)
            
            # ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •
            if execution.retry_count < schedule.max_retries:
                execution.retry(error_msg)
                logger.warning(f"âš ï¸ íŒŒì´í”„ë¼ì¸ ì¬ì‹œë„ ì˜ˆì •: {pipeline_id} (ì¬ì‹œë„: {execution.retry_count}/{schedule.max_retries})")
                # TODO: ì‹¤ì œ ì¬ì‹œë„ ë¡œì§ êµ¬í˜„ (ë³„ë„ ìŠ¤ë ˆë“œë‚˜ ì§€ì—° ì‹¤í–‰ ë“±)
            else:
                execution.complete(success=False, error_message=error_msg)
                logger.error(f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¢…ë£Œ: {pipeline_id}")
        
        # ì‹¤í–‰ ê¸°ë¡ ì²˜ë¦¬
        del self.running_executions[execution.id]
        self.completed_executions.append(execution)
        self._save_execution_record(execution)
        
        # ì½œë°± í˜¸ì¶œ
        if self.on_execution_complete:
            self.on_execution_complete(execution)
    
    def run_scheduler(self, interval: int = 60):
        """
        ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ë£¨í”„
        
        Args:
            interval: ìŠ¤ì¼€ì¤„ í™•ì¸ ê°„ê²©(ì´ˆ)
        """
        logger.info("ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨")
        try:
            while True:
                self.run_once()
                time.sleep(interval)
        except KeyboardInterrupt:
            logger.info("ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ë¨")
    
    def _save_execution_record(self, execution: ExecutionRecord):
        """ì‹¤í–‰ ê¸°ë¡ ì €ì¥"""
        record_path = self.history_dir / f"{execution.id}.json"
        with open(record_path, 'w', encoding='utf-8') as f:
            json.dump(execution.to_dict(), f, indent=2, ensure_ascii=False)
    
    def _save_schedules(self):
        """ëª¨ë“  ìŠ¤ì¼€ì¤„ ì„¤ì • ì €ì¥"""
        # ìŠ¤ì¼€ì¤„ ì •ë³´ ì €ì¥
        schedules_data = {}
        for schedule_id, schedule in self.schedules.items():
            schedules_data[schedule_id] = schedule.to_dict()
        
        # ìŠ¤ì¼€ì¤„ JSON íŒŒì¼ ì €ì¥
        schedules_path = self.schedule_dir / "schedules.json"
        with open(schedules_path, 'w', encoding='utf-8') as f:
            json.dump(schedules_data, f, indent=2, ensure_ascii=False)
        
        logger.debug(f"ìŠ¤ì¼€ì¤„ ì •ë³´ê°€ {schedules_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _load_schedules(self):
        """ì €ì¥ëœ ìŠ¤ì¼€ì¤„ ì •ë³´ ë¡œë“œ"""
        schedules_path = self.schedule_dir / "schedules.json"
        if not schedules_path.exists():
            logger.info("ì €ì¥ëœ ìŠ¤ì¼€ì¤„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        try:
            with open(schedules_path, 'r', encoding='utf-8') as f:
                schedules_data = json.load(f)
                
            for schedule_id, schedule_data in schedules_data.items():
                schedule = ScheduleConfig.from_dict(schedule_data, self.schedule_dir)
                self.schedules[schedule_id] = schedule
                
            logger.info(f"{len(self.schedules)}ê°œì˜ ìŠ¤ì¼€ì¤„ ì •ë³´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"ìŠ¤ì¼€ì¤„ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _load_history(self):
        """ì €ì¥ëœ ì‹¤í–‰ ì´ë ¥ ë¡œë“œ"""
        if not self.history_dir.exists():
            return
            
        for file_path in self.history_dir.glob("*.json"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                # ì‹¤í–‰ ê¸°ë¡ ë³µì› (ê°„ì†Œí™” ë²„ì „)
                record = ExecutionRecord(data["schedule_id"], data["pipeline_id"])
                record.id = data["id"]
                record.start_time = datetime.fromisoformat(data["start_time"])
                if data["end_time"]:
                    record.end_time = datetime.fromisoformat(data["end_time"])
                record.status = data["status"]
                record.retry_count = data["retry_count"]
                record.error_message = data["error_message"]
                record.logs = data.get("logs", [])
                
                self.completed_executions.append(record)
            except Exception as e:
                logger.error(f"ì‹¤í–‰ ì´ë ¥ ë¡œë“œ ì‹¤íŒ¨: {file_path} - {e}")
        
        logger.info(f"{len(self.completed_executions)}ê°œì˜ ì‹¤í–‰ ì´ë ¥ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.") 