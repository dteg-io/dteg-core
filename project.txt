# 🚀 dteg: 데이터 엔지니어링 프레임워크

## **1. 아키텍처 개요**

### **📌 핵심 구성 요소**

dteg 프레임워크는 **8가지 주요 컴포넌트**로 구성됩니다.

1️⃣ **Extractor (데이터 추출 모듈)**

- API, 데이터베이스(MySQL, PostgreSQL 등), 파일(CSV, JSON) 등에서 데이터를 가져오는 모듈.
- 데이터 커넥터를 플러그인 형태로 지원.
- 증분 추출 지원 및 소스 시스템 부하 최소화

2️⃣ **Loader (데이터 적재 모듈)**

- 데이터를 목적지(BigQuery, Snowflake, S3 등)로 저장.
- 대량의 데이터를 효율적으로 처리하기 위해 **Batch & Streaming 방식 지원**.
- 데이터 압축 및 최적화된 적재 전략 지원

3️⃣ **Transformer (변환 모듈)**

- 적재된 데이터를 SQL 기반으로 변환.
- dbt와 연동하여 기존 SQL 변환 스크립트를 쉽게 적용 가능.
- 데이터 품질 검사 자동화

4️⃣ **Security Manager (보안 관리 모듈)**

- AES-256 기반 데이터 암호화
- RBAC(Role-Based Access Control) 접근 제어
- OAuth2/JWT 기반 인증
- 데이터 마스킹 및 익명화
- 감사 로그 기록

5️⃣ **Quality Controller (품질 관리 모듈)**

- Great Expectations 기반 데이터 검증
- 실시간 데이터 프로파일링
- 스키마 변경 감지 및 알림
- 데이터 품질 메트릭스 대시보드

6️⃣ **Governance Hub (거버넌스 모듈)**

- 데이터 카탈로그 관리 (Amundsen 연동)
- 데이터 계보 추적 (OpenLineage 통합)
- GDPR, CCPA 등 규정 준수 모니터링
- 메타데이터 자동 수집 및 관리

7️⃣ **Orchestrator (스케줄러 & 실행 관리)**

- ELT 파이프라인을 정의하고 실행 스케줄을 관리.
- 실행 로그, 실패한 태스크 재시도 기능 제공.
- 분산 실행 환경 지원
- 실시간 모니터링 및 알림

8️⃣ **Marketplace (컴포넌트 공유 플랫폼)**

- 커뮤니티 기반 컴포넌트 공유 시스템
- 품질 관리 및 검증 프로세스
- 버전 관리 및 호환성 체크
- 평가 및 리뷰 시스템

---

### **📌 아키텍처 다이어그램**

```
                        +----------------+
                        | Marketplace    |
                        | Platform       |
                        +----------------+
                                ↓
                        +----------------+
                        | Security       |
                        | Manager        |
                        +----------------+
                                ↓
        +-------------+  +--------------+  +--------------+
        | Extractor   |->| Loader       |->| Transformer  |
        +-------------+  +--------------+  +--------------+
                ↑               ↑                  ↑
                |               |                  |
    +----------------+ +----------------+ +----------------+
    | Quality        | | Governance     | | Orchestrator   |
    | Controller     | | Hub            | | (FastAPI + UI) |
    +----------------+ +----------------+ +----------------+
```

---

## **2. 기술 스택**

### **🔹 핵심 기술**

| 영역 | 기술 스택 | 설명 |
|-----|---------|-----|
| **데이터 추출** | Python (pandas, requests, SQLAlchemy) | 다양한 데이터 소스 지원 |
| **데이터 적재** | Google BigQuery, Snowflake, AWS S3 | 데이터 웨어하우스 적재 |
| **데이터 변환** | dbt, SQL | SQL 기반 변환, dbt 연동 |
| **보안** | Vault, JWT, OAuth2, AES | 암호화 및 인증 관리 |
| **품질관리** | Great Expectations, dbt tests | 데이터 검증 |
| **거버넌스** | OpenLineage, Amundsen | 데이터 계보 및 카탈로그 |
| **오케스트레이션** | FastAPI, Celery, Redis | 파이프라인 실행 & 스케줄링 |
| **모니터링** | Prometheus, Grafana, AlertManager | 메트릭스 및 알림 |
| **웹 UI** | React (Next.js), TailwindCSS | 실행 상태 모니터링 |
| **배포 환경** | Docker, K8s, AWS, GCP | 클라우드 & 온프레미스 |
| **마켓플레이스** | FastAPI, React, MongoDB | 컴포넌트 공유 플랫폼 |

---

## **3. 실행 방식 & 예제**

**✅ YAML 기반 설정 파일 예시**

```yaml
pipeline:
  name: "example_elt"
  schedule: "0 12 * * *"  # 매일 12시에 실행
  
  components:
    marketplace:
      - name: "kafka-extractor"
        version: "1.0.0"
        source: "dteg://streaming/kafka"
      - name: "salesforce-loader"
        version: "2.1.0"
        source: "dteg://enterprise/salesforce"
  
  security:
    encryption: true
    access_level: "restricted"
    data_masking: ["email", "phone"]
  
  quality:
    validation_rules:
      - type: "null_check"
        columns: ["id", "email"]
      - type: "format_check"
        column: "email"
        pattern: "^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$"
  
  steps:
    - extract:
        type: "dteg://kafka-extractor"
        config:
          bootstrap_servers: "kafka:9092"
          topic_name: "data-stream"
    - load:
        type: "dteg://salesforce-loader"
        config:
          api_version: "v53.0"
          object_name: "Contact"
    - transform:
        type: "dbt"
        model: "transformation_script.sql"
        tests: true

  monitoring:
    alerts:
      - type: "slack"
        channel: "#data-alerts"
      - type: "email"
        recipients: ["data-team@company.com"]
```

- **Extract:** API에서 데이터 가져오기
- **Load:** BigQuery 테이블에 적재
- **Transform:** dbt 모델을 실행해 변환

---

## **4. 차별점 & 기대 효과**

✅ **가볍고 빠른 ELT 프레임워크** → Airflow, Airbyte보다 설정이 간편

✅ **YAML 기반 설정으로 쉽게 파이프라인 구성 가능**

✅ **dbt 연동 지원 → SQL 기반 변환을 간편하게 실행**

✅ **클라우드 & 서버리스 환경에서도 가볍게 실행 가능**

---

# **1️⃣ 기능 개발 순서 (로드맵)**

### **🚀 1단계: 기본 구조 & 핵심 기능 개발**

✅ **프로젝트 기본 구조 설정**

- FastAPI 기반 REST API 서버 구축
- CLI 인터페이스 기본 구조 정의

✅ **데이터 추출 (Extractor) 구현**

- API, MySQL, PostgreSQL에서 데이터 추출 기능 추가
- 간단한 JSON/YAML 설정으로 데이터 소스 연결 가능하도록 개발

✅ **데이터 적재 (Loader) 구현**

- Google BigQuery, Snowflake, AWS S3로 적재 기능 추가

✅ **간단한 실행 테스트**

- 기본적인 Extract → Load 흐름이 동작하는지 확인

---

### **⚡ 2단계: 변환(Transform) 및 ELT 파이프라인 완성**

✅ **dbt 연동 기능 추가**

- 적재된 데이터를 SQL 기반으로 변환하는 기능 구현

✅ **스케줄링 & 오케스트레이션 추가**

- Celery + Redis를 이용해 배치 실행 지원
- YAML 설정 파일을 기반으로 ELT 파이프라인 실행 가능하도록 개선

✅ **웹 UI 기본 버전 개발**

- 실행 상태 모니터링 가능한 대시보드 (React + FastAPI)

✅ **에러 핸들링 & 로깅 추가**

- 실패한 작업을 자동으로 재시도하는 기능
- 실행 로그를 Prometheus + Grafana로 관리

---

### **🔥 3단계: 최적화 및 배포**

✅ **Docker 컨테이너화 & 배포 지원**

- AWS Lambda, GCP Cloud Run에서 실행 가능하도록 최적화

✅ **추가 데이터 소스 지원**

- CSV, Google Sheets, Kafka, MongoDB 등 확장

✅ **웹 UI 고도화**

- 실행 히스토리 조회, 로그 확인 기능 추가

✅ **테스트 및 성능 최적화**

- 병렬 처리 최적화, 대용량 데이터 처리 개선

---

### **🚀 4단계: 마켓플레이스 구축**

✅ **마켓플레이스 기본 인프라 구축**
- 컴포넌트 저장소 설계 및 구현
- 버전 관리 시스템 구축
- 검색 및 필터링 기능 개발

✅ **품질 관리 시스템 구축**
- 자동화된 테스트 파이프라인
- 보안 취약점 스캔 시스템
- 성능 테스트 프레임워크

✅ **커뮤니티 기능 개발**
- 사용자 리뷰 및 평가 시스템
- 문서화 템플릿 및 가이드라인
- 커뮤니티 포럼 및 지원 시스템

✅ **수익화 모델 구축**
- 프리미엄 컴포넌트 결제 시스템
- 기업용 라이선스 관리
- 사용량 기반 과금 시스템

### **마켓플레이스 컴포넌트 표준**

```yaml
component_standard:
  metadata:
    manifest:
      - name
      - version
      - author
      - description
      - category
      - pricing
    
    compatibility:
      - framework_versions
      - python_versions
      - system_requirements
    
    documentation:
      - overview
      - configuration
      - examples
      - troubleshooting
    
  quality_gates:
    required:
      - security_scan: pass
      - test_coverage: >= 80%
      - documentation: complete
      - performance_test: pass
    
    optional:
      - community_rating: >= 4.0
      - monthly_downloads: >= 1000
```

## 🏪 dteg 마켓플레이스

### 컴포넌트 설치
```bash
# 커넥터 검색
dteg search kafka

# 커넥터 설치
dteg install marketplace://kafka-extractor

# 커넥터 업데이트
dteg update marketplace://kafka-extractor
```

### 컴포넌트 개발 및 배포
```bash
# 새 커넥터 프로젝트 생성
dteg create connector my-connector

# 커넥터 테스트
dteg test my-connector

# 마켓플레이스에 배포
dteg publish my-connector
```

### 지원되는 컴포넌트 유형
✔ Extractors (데이터 추출기)
✔ Loaders (데이터 적재기)
✔ Transformers (데이터 변환기)
✔ Custom Processors (사용자 정의 처리기)

## **결론: dteg 프로젝트의 대상 사용자**
- **데이터 엔지니어** → ELT 파이프라인을 쉽게 구축하고 싶은 사람
- **스타트업 & 중소기업** → 복잡한 Airflow 없이 빠르게 데이터 파이프라인을 구축하려는 팀
- **프리랜서 & 개발자** → 개인 프로젝트에서 ELT를 가볍게 활용하고 싶은 사람
- **데이터 커뮤니티** → 커스텀 컴포넌트를 개발하고 공유하고 싶은 개발자
